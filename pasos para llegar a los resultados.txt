1. Abrir en Jupyter, Google colab, etc los archivos base 1T-2016, base 1T-2017base, 1T-2018, base 1T-2019, base 2T-2016,base 1T-2016, base 1T-2017base, 1T-2018, base 1T-2019, base 2T-2016, base 2T-2017, base, 2T-2018, base 2T-2019, base 3T-2016, base 3T-2017,base, 3T-2018, base 3T-2019, base 4T-2016, base 4T-2017,base, 4T-2018, base 4T-2019.para el cual se reequieren los 16 archivos.csv de la carpeta Bases de datos encuenta continua de empleo. 
2. Hacer correr los archivos .ipynb mencionados en el punto 1, como resulatdos se obtiene 16 archivos tipo .csv nombrado df_1t_2016,df_1t_2017,df_1t_2018,df_1t_2019,df_2t_2016,df_2t_2017,df_2t_2018,df_2t_2019, df_3t_2016,df_3t_2017,df_3t_2018,df_3t_2019,df_4t_2016,df_4t_2017,df_4t_2018,df_4t_2019. 
3. Abrir y hacer correr los archivos .ipynb nombrados 1t-2016-2019, 2t-2016_2019, 3t-2016_2019 y 4t-2016_2019.donde se encuenbtra todo el analisis descriptivo estadistico, y la limpieza de datos. 
4. Abrir y ahcer correr los archivos .ipynb nombrados 1t_Mod_final, 2t_Mod_final, 3t_Mod_final y 4t_Mod_final, en el que se encuentran los tres modelos de arbol, tanto el entrenamiento como la evaluaci√≥n. 
5.abrir y hacer correr el archivo .ipynb Series de tiempo, en el que se encuenrtra el modelo SARIMA. 